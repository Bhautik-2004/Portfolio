---
title: "2025 Wrapped"
publishedAt: "2026-01-05"
summary: "Year of pure Machine Learning"
tags: "Personal, 2025"
---

```bash
git commit -m "Year of pure Machine Learning"
```

Welcome to my first-ever year-in-review. To be honest, I'm much more comfortable 
writing code than writing about myself, so this is all pretty new to me. 
I've never done a public recap before, but after a big year of diving into 
Python and Machine Learning and where I'm headed next.


## Images of the Year
<div
  style={{
    display: 'grid',
    gridTemplateColumns: 'repeat(auto-fit, minmax(280px, 1fr))',
    gap: '24px',
    alignItems: 'start',
  }}
>
  <div>
    <Image
      src="/photos/GDG-AHM-2025-2.jpeg"
      alt="GDG Ahmedabad 2025"
      width={500}
      height={400}
    />
    <Caption>
      _10th Aug 2025:_ Solid day at GDG Ahmedabad learning all things Google Cloud. Good vibes, great friends, and a lot of new cloud knowledge.
    </Caption>
  </div>

  <div>
    <Image
      src="/photos/SSIP-2025.jpeg"
      alt="SSIP 2025"
      width={500}
      height={400}
    />
    <Caption>
      _16th Dec 2025:_ Presentation day for SSIP 2025 _(GLS Law Laboratory (Container))_.
    </Caption>
  </div>
</div>


## Skills and Deep Dives
This year, I intentionally went back to the basics, especially pure 
Object-Oriented Programming. I moved away from writing mostly linear, 
procedural code and started thinking in terms of systems and entities. 
Treating everything as an object helped me reason better about state, 
behavior, and how different parts of a system interact, which is crucial 
when building things that need to scale.

A large part of my learning came from structured academic material. 
I spent time with [IIT Madras YouTube Playlist](https://www.youtube.com/watch?v=KMcUe7GQnf0&list=PLZ2ps__7DhBbA_e6_G3FI-BA1f7lCINUu) 
and the [Cornell University Spring course](https://www.cs.cornell.edu/courses/cs4780/2024sp/). 
These were not quick tutorials but deep academic dives 
that pushed me to understand why things work, not just how to use them.

Alongside this, I revisited [Introduction to Statistical Learning 
with Applications in Python](https://www.statlearning.com/) as a core reference, especially for topics 
like resampling methods and regularization. Combining Cornell's theoretical 
rigor with ISLP's practical framing helped me move beyond just calling library 
functions to actually understanding loss optimization and the bias-variance tradeoff.
Also earned certificate on NPTEL in Introduction to Machine Learning.

By the end of the year, I felt a clear shift in how I think. Instead of 
asking which model or tool to use, I started asking what assumptions I am making 
and how those choices affect generalization.

### Learned by Solo
A lot of this learning happened alone. No fixed deadlines, 
just me, the material, and the discomfort of not understanding things immediately. 
Studying this way forced me to sit with confusion longer, revisit the same concepts 
multiple times, and build my own mental models instead of copying solutions. 
It was slower, but it made the understanding stick.

I also used AI to make sense of a few tricky topics. Turns out having something 
that never gets tired of dumb questions is incredibly useful. Totally worth it! üòÅ

## Projects
This year, I also co-founded [Colrnx](https://colrnx.com) with [Vashisht Brahmbhatt](https://www.instagram.com/vashishtdb/) and [Daksh Patel](https://www.instagram.com/dakx.exe/). Most of the work so far has gone into shaping 
the idea, defining the direction, and building a solid foundation rather than rushing 
to ship. It's still early, but the plan is to launch it sometime in 2026, and I'm excited 
to see how it evolves from here.


## Things that didn't work
I tried getting into the creative side this year, things like content writing 
and video editing, but it didn't really work out. Nothing much to elaborate it.

## Carrying this forward
Going ahead, I want to go deeper into machine learning instead of spreading myself thin. 
This means spending more time with tools like scikit-learn and PyTorch, getting better 
at data preprocessing, and understanding how real-world data is shaped before it 
ever reaches a model. I also want to slowly build the habit of reading research papers, 
not to rush results, but to get comfortable with how ideas are explored and validated.

## Benchmarks/Stats
<Table
  data={{
    headers: ["Metric", "This year"],
    rows: [
      [
        "Most played game",
        "Valorant, Minecraft",
      ],
      [
        "Most ignored habit",
        "Sleeping on time",
      ],
      [
        "Most asked question (to AI)",
        "Wait, but why?",
      ],
      [
        "Most time spent",
        "Thinking something would ‚Äúonly take 30 minutes.‚Äù",
      ],
      [
        "Most surprising helper",
        "AI",
      ],
      [
        "Most consistent activity",
        "Overthinking",
      ]
    ],
  }}
/>


_That's it! I'm glad I took the time to write it down._